{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIkOfqyn4VLD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bac5012-ca4f-48b6-d49f-d07a7bf35e7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# CELL 1: Install Required Libraries\n",
        "# =============================================================================\n",
        "!pip install streamlit flask flask-ngrok pyngrok pandas numpy matplotlib seaborn scikit-learn -q\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 2: Setup ngrok for tunneling (Required for Colab)\n",
        "# =============================================================================\n",
        "# You need to get a free authtoken from https://ngrok.com/\n",
        "# Sign up and get your authtoken, then run:\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Replace 'YOUR_NGROK_AUTHTOKEN' with your actual token\n",
        "# ngrok.set_auth_token(\"YOUR_NGROK_AUTHTOKEN\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "072445ee",
        "outputId": "431ba351-a1c8-4ffc-a185-8eaf6d5c7c2a"
      },
      "source": [
        "# =============================================================================\n",
        "# CELL 3: Create the Main Application File\n",
        "# =============================================================================\n",
        "%%writefile duplicate_remover_core.py\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import warnings\n",
        "import io\n",
        "import base64\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "class TextDuplicateRemover:\n",
        "    def __init__(self, n_clusters=10, similarity_threshold=0.8):\n",
        "        self.n_clusters = n_clusters\n",
        "        self.similarity_threshold = similarity_threshold\n",
        "        self.vectorizer = None\n",
        "        self.kmeans = None\n",
        "        self.pca = None\n",
        "\n",
        "    def create_text_features(self, texts):\n",
        "        \"\"\"\n",
        "        Create numerical features from text using simple character and word counts\n",
        "        \"\"\"\n",
        "        features = []\n",
        "        for text in texts:\n",
        "            text = str(text)\n",
        "            feature_vector = [\n",
        "                len(text),\n",
        "                text.count(' '),\n",
        "                sum(c.isupper() for c in text),\n",
        "                sum(c.islower() for c in text),\n",
        "                sum(c.isdigit() for c in text),\n",
        "                sum(c in '.,;:!?()[]{}' for c in text),\n",
        "                len(text.split()),\n",
        "                len(set(text.split())),\n",
        "                len(text) / max(1, len(text.split())),\n",
        "            ]\n",
        "            for char in 'abcdefghij':\n",
        "                feature_vector.append(text.lower().count(char) / max(1, len(text)))\n",
        "            features.append(feature_vector)\n",
        "        return np.array(features)\n",
        "\n",
        "    def find_duplicates(self, texts):\n",
        "        \"\"\"\n",
        "        Find duplicate texts using K-means clustering\n",
        "        \"\"\"\n",
        "        if len(texts) < 2:\n",
        "            return []\n",
        "\n",
        "        features = self.create_text_features(texts)\n",
        "        scaler = StandardScaler()\n",
        "        features_scaled = scaler.fit_transform(features)\n",
        "\n",
        "        n_components = min(features_scaled.shape[0], features_scaled.shape[1], 10)\n",
        "        if n_components < 1:\n",
        "            return []\n",
        "\n",
        "        self.pca = PCA(n_components=n_components)\n",
        "        features_pca = self.pca.fit_transform(features_scaled)\n",
        "\n",
        "        actual_n_clusters = min(self.n_clusters, len(texts))\n",
        "        if actual_n_clusters < 2:\n",
        "            return []\n",
        "\n",
        "        self.kmeans = KMeans(n_clusters=actual_n_clusters, random_state=42, n_init=10)\n",
        "        clusters = self.kmeans.fit_predict(features_pca)\n",
        "\n",
        "        duplicates = []\n",
        "        for cluster_id in range(actual_n_clusters):\n",
        "            cluster_indices = np.where(clusters == cluster_id)[0]\n",
        "            if len(cluster_indices) > 1:\n",
        "                for i in range(len(cluster_indices)):\n",
        "                    for j in range(i + 1, len(cluster_indices)):\n",
        "                        idx1, idx2 = cluster_indices[i], cluster_indices[j]\n",
        "                        dist = np.linalg.norm(features_pca[idx1] - features_pca[idx2])\n",
        "                        similarity = 1 / (1 + dist)\n",
        "                        if similarity > self.similarity_threshold:\n",
        "                            found_group = False\n",
        "                            for group in duplicates:\n",
        "                                if idx1 in group:\n",
        "                                    group.append(idx2)\n",
        "                                    found_group = True\n",
        "                                    break\n",
        "                                elif idx2 in group:\n",
        "                                    group.append(idx1)\n",
        "                                    found_group = True\n",
        "                                    break\n",
        "                            if not found_group:\n",
        "                                duplicates.append([idx1, idx2])\n",
        "\n",
        "        duplicates = [list(set(group)) for group in duplicates if len(set(group)) > 1]\n",
        "        return duplicates\n",
        "\n",
        "    def visualize_clusters(self, texts):\n",
        "        \"\"\"\n",
        "        Visualize text clusters and return figure\n",
        "        \"\"\"\n",
        "        if len(texts) < 2:\n",
        "            return None\n",
        "\n",
        "        features = self.create_text_features(texts)\n",
        "        scaler = StandardScaler()\n",
        "        features_scaled = scaler.fit_transform(features)\n",
        "\n",
        "        n_components = min(2, features_scaled.shape[0], features_scaled.shape[1])\n",
        "        if n_components < 2:\n",
        "            return None\n",
        "\n",
        "        pca = PCA(n_components=n_components)\n",
        "        features_2d = pca.fit_transform(features_scaled)\n",
        "\n",
        "        actual_n_clusters = min(self.n_clusters, len(texts))\n",
        "        if actual_n_clusters < 2:\n",
        "            return None\n",
        "\n",
        "        kmeans = KMeans(n_clusters=actual_n_clusters, random_state=42, n_init=10)\n",
        "        clusters = kmeans.fit_predict(features_2d)\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        scatter = ax.scatter(features_2d[:, 0], features_2d[:, 1], c=clusters, cmap='viridis', alpha=0.6)\n",
        "        plt.colorbar(scatter, ax=ax, label='Cluster')\n",
        "        ax.set_title('Text Clusters Visualization')\n",
        "        ax.set_xlabel('Principal Component 1')\n",
        "        ax.set_ylabel('Principal Component 2')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "\n",
        "class TabularDuplicateRemover:\n",
        "    def __init__(self, similarity_threshold=0.9):\n",
        "        self.similarity_threshold = similarity_threshold\n",
        "        self.scaler = StandardScaler()\n",
        "        self.pca = None\n",
        "        self.kmeans = None\n",
        "        self.knn = None\n",
        "\n",
        "    def find_exact_duplicates(self, df):\n",
        "        \"\"\"\n",
        "        Find exact duplicate rows\n",
        "        \"\"\"\n",
        "        if df.empty:\n",
        "            return []\n",
        "\n",
        "        duplicates = df.duplicated(keep=False)\n",
        "        duplicate_rows = df[duplicates]\n",
        "        duplicate_groups = []\n",
        "        processed = set()\n",
        "\n",
        "        for idx in duplicate_rows.index:\n",
        "            if idx in processed:\n",
        "                continue\n",
        "            mask = (df == df.loc[idx]).all(axis=1)\n",
        "            group = df[mask].index.tolist()\n",
        "            if len(group) > 1:\n",
        "                duplicate_groups.append(group)\n",
        "                processed.update(group)\n",
        "\n",
        "        return duplicate_groups\n",
        "\n",
        "    def find_near_duplicates_kmeans(self, df, numeric_columns=None):\n",
        "        \"\"\"\n",
        "        Find near-duplicate rows using K-means clustering\n",
        "        \"\"\"\n",
        "        if numeric_columns is None:\n",
        "            numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "        if not numeric_columns or len(df) < 2:\n",
        "            return []\n",
        "\n",
        "        data = df[numeric_columns].fillna(0)\n",
        "        data_scaled = self.scaler.fit_transform(data)\n",
        "\n",
        "        n_components = min(10, len(numeric_columns), len(df))\n",
        "        if n_components < 1:\n",
        "            return []\n",
        "\n",
        "        self.pca = PCA(n_components=n_components)\n",
        "        data_pca = self.pca.fit_transform(data_scaled)\n",
        "\n",
        "        n_clusters = min(20, max(2, len(df) // 5))\n",
        "        self.kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "        clusters = self.kmeans.fit_predict(data_pca)\n",
        "\n",
        "        duplicate_groups = []\n",
        "        for cluster_id in range(n_clusters):\n",
        "            cluster_indices = np.where(clusters == cluster_id)[0].tolist()\n",
        "            if len(cluster_indices) > 1:\n",
        "                for i in range(len(cluster_indices)):\n",
        "                    for j in range(i + 1, len(cluster_indices)):\n",
        "                        idx1, idx2 = cluster_indices[i], cluster_indices[j]\n",
        "                        dist = np.linalg.norm(data_pca[idx1] - data_pca[idx2])\n",
        "                        similarity = 1 / (1 + dist)\n",
        "                        if similarity > self.similarity_threshold:\n",
        "                            found_group = False\n",
        "                            for group in duplicate_groups:\n",
        "                                if idx1 in group:\n",
        "                                    group.append(idx2)\n",
        "                                    found_group = True\n",
        "                                    break\n",
        "                                elif idx2 in group:\n",
        "                                    group.append(idx1)\n",
        "                                    found_group = True\n",
        "                                    break\n",
        "                            if not found_group:\n",
        "                                duplicate_groups.append([idx1, idx2])\n",
        "\n",
        "        return [list(set(g)) for g in duplicate_groups if len(set(g)) > 1]\n",
        "\n",
        "    def find_near_duplicates_knn(self, df, numeric_columns=None, n_neighbors=5):\n",
        "        \"\"\"\n",
        "        Find near-duplicates using K-Nearest Neighbors\n",
        "        \"\"\"\n",
        "        if numeric_columns is None:\n",
        "            numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "        if not numeric_columns or len(df) < 2:\n",
        "            return []\n",
        "\n",
        "        data = df[numeric_columns].fillna(0)\n",
        "        data_scaled = self.scaler.fit_transform(data)\n",
        "\n",
        "        n_components = min(10, len(numeric_columns), len(df))\n",
        "        if n_components < 1:\n",
        "            return []\n",
        "\n",
        "        self.pca = PCA(n_components=n_components)\n",
        "        data_pca = self.pca.fit_transform(data_scaled)\n",
        "\n",
        "        actual_n_neighbors = min(n_neighbors, len(data_pca))\n",
        "        self.knn = NearestNeighbors(n_neighbors=actual_n_neighbors)\n",
        "        self.knn.fit(data_pca)\n",
        "\n",
        "        distances, indices = self.knn.kneighbors(data_pca)\n",
        "        duplicate_groups = []\n",
        "        processed = set()\n",
        "\n",
        "        for i in range(len(data_pca)):\n",
        "            if i in processed:\n",
        "                continue\n",
        "            group = [i]\n",
        "            for j, dist in zip(indices[i], distances[i]):\n",
        "                if j != i and j not in processed and dist < (1 - self.similarity_threshold):\n",
        "                    group.append(j)\n",
        "                    processed.add(j)\n",
        "            if len(group) > 1:\n",
        "                duplicate_groups.append(group)\n",
        "                processed.add(i)\n",
        "\n",
        "        return duplicate_groups\n",
        "\n",
        "    def visualize_clusters(self, df, numeric_columns=None):\n",
        "        \"\"\"\n",
        "        Visualize data clusters and return figure\n",
        "        \"\"\"\n",
        "        if numeric_columns is None:\n",
        "            numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "        if len(numeric_columns) < 2 or len(df) < 2:\n",
        "            return None\n",
        "\n",
        "        data = df[numeric_columns].fillna(0)\n",
        "        data_scaled = self.scaler.fit_transform(data)\n",
        "\n",
        "        pca = PCA(n_components=2)\n",
        "        data_2d = pca.fit_transform(data_scaled)\n",
        "\n",
        "        n_clusters = min(10, max(2, len(df) // 5))\n",
        "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "        clusters = kmeans.fit_predict(data_2d)\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        scatter = ax.scatter(data_2d[:, 0], data_2d[:, 1], c=clusters, cmap='viridis', alpha=0.6)\n",
        "        plt.colorbar(scatter, ax=ax, label='Cluster')\n",
        "        ax.set_title('Data Clusters Visualization')\n",
        "        ax.set_xlabel('Principal Component 1')\n",
        "        ax.set_ylabel('Principal Component 2')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "\n",
        "class ClassificationDuplicateDetector:\n",
        "    def __init__(self, method='random_forest'):\n",
        "        self.method = method\n",
        "        self.model = None\n",
        "        self.scaler = StandardScaler()\n",
        "        self.pca = None\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.is_trained = False\n",
        "\n",
        "    def create_training_data(self, df, numeric_columns=None):\n",
        "        \"\"\"\n",
        "        Create training data for duplicate detection\n",
        "        \"\"\"\n",
        "        if numeric_columns is None:\n",
        "            numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "        if len(numeric_columns) < 1 or len(df) < 2:\n",
        "            return None, None\n",
        "\n",
        "        data = df[numeric_columns].fillna(0)\n",
        "        pairs = []\n",
        "        labels = []\n",
        "\n",
        "        for i in range(len(data)):\n",
        "            for j in range(i + 1, len(data)):\n",
        "                if (data.iloc[i] == data.iloc[j]).all():\n",
        "                    pairs.append(np.concatenate([data.iloc[i].values, data.iloc[j].values]))\n",
        "                    labels.append(1)\n",
        "\n",
        "        for i in range(len(data)):\n",
        "            for j in range(i + 1, min(i + 10, len(data))):\n",
        "                if not (data.iloc[i] == data.iloc[j]).all():\n",
        "                    pairs.append(np.concatenate([data.iloc[i].values, data.iloc[j].values]))\n",
        "                    labels.append(0)\n",
        "\n",
        "        if len(pairs) == 0:\n",
        "            return None, None\n",
        "\n",
        "        return np.array(pairs), np.array(labels)\n",
        "\n",
        "    def train_model(self, X, y):\n",
        "        \"\"\"\n",
        "        Train classification model\n",
        "        \"\"\"\n",
        "        if X is None or y is None or len(X) < 2:\n",
        "            return 0.0\n",
        "\n",
        "        if len(np.unique(y)) < 2:\n",
        "            return 0.0\n",
        "\n",
        "        X_scaled = self.scaler.fit_transform(X)\n",
        "        n_components = min(20, X.shape[1], X.shape[0])\n",
        "        self.pca = PCA(n_components=n_components)\n",
        "        X_pca = self.pca.fit_transform(X_scaled)\n",
        "\n",
        "        test_size = min(0.2, max(0.1, 2 / len(X)))\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X_pca, y, test_size=test_size, random_state=42, stratify=y if len(np.unique(y)) > 1 else None\n",
        "        )\n",
        "\n",
        "        if self.method == 'logistic_regression':\n",
        "            self.model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "        elif self.method == 'svm':\n",
        "            self.model = SVC(random_state=42, probability=True)\n",
        "        elif self.method == 'decision_tree':\n",
        "            self.model = DecisionTreeClassifier(random_state=42)\n",
        "        else:\n",
        "            self.model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "\n",
        "        self.model.fit(X_train, y_train)\n",
        "        self.is_trained = True\n",
        "\n",
        "        y_pred = self.model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        return accuracy\n",
        "\n",
        "    def find_duplicates(self, df, numeric_columns=None, threshold=0.5):\n",
        "        \"\"\"\n",
        "        Find duplicates using trained model\n",
        "        \"\"\"\n",
        "        if not self.is_trained or self.model is None:\n",
        "            return []\n",
        "\n",
        "        if numeric_columns is None:\n",
        "            numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "        if not numeric_columns or len(df) < 2:\n",
        "            return []\n",
        "\n",
        "        data = df[numeric_columns].fillna(0)\n",
        "        pairs = []\n",
        "        indices = []\n",
        "\n",
        "        for i in range(len(data)):\n",
        "            for j in range(i + 1, len(data)):\n",
        "                pairs.append(np.concatenate([data.iloc[i].values, data.iloc[j].values]))\n",
        "                indices.append((i, j))\n",
        "\n",
        "        if not pairs:\n",
        "            return []\n",
        "\n",
        "        try:\n",
        "            pairs_scaled = self.scaler.transform(pairs)\n",
        "            pairs_pca = self.pca.transform(pairs_scaled)\n",
        "            probabilities = self.model.predict_proba(pairs_pca)[:, 1]\n",
        "        except Exception:\n",
        "            return []\n",
        "\n",
        "        duplicate_groups = []\n",
        "        processed = set()\n",
        "\n",
        "        for (i, j), prob in zip(indices, probabilities):\n",
        "            if prob > threshold and i not in processed and j not in processed:\n",
        "                found_group = False\n",
        "                for group in duplicate_groups:\n",
        "                    if i in group:\n",
        "                        group.append(j)\n",
        "                        processed.add(j)\n",
        "                        found_group = True\n",
        "                        break\n",
        "                    elif j in group:\n",
        "                        group.append(i)\n",
        "                        processed.add(i)\n",
        "                        found_group = True\n",
        "                        break\n",
        "                if not found_group:\n",
        "                    duplicate_groups.append([i, j])\n",
        "                    processed.add(i)\n",
        "                    processed.add(j)\n",
        "\n",
        "        return duplicate_groups\n",
        "\n",
        "    def compare_models(self, df, numeric_columns=None):\n",
        "        \"\"\"\n",
        "        Compare different classification models\n",
        "        \"\"\"\n",
        "        if numeric_columns is None:\n",
        "            numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "        X, y = self.create_training_data(df, numeric_columns)\n",
        "        if X is None or y is None:\n",
        "            return {}\n",
        "\n",
        "        models = {\n",
        "            'Logistic Regression': 'logistic_regression',\n",
        "            'SVM': 'svm',\n",
        "            'Decision Tree': 'decision_tree',\n",
        "            'Random Forest': 'random_forest'\n",
        "        }\n",
        "\n",
        "        results = {}\n",
        "        for name, method in models.items():\n",
        "            self.method = method\n",
        "            accuracy = self.train_model(X, y)\n",
        "            results[name] = accuracy\n",
        "\n",
        "        return results\n",
        "\n",
        "    def plot_model_comparison(self, results):\n",
        "        \"\"\"\n",
        "        Plot model comparison results\n",
        "        \"\"\"\n",
        "        if not results:\n",
        "            return None\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        bars = ax.bar(results.keys(), results.values(), color=['#3498db', '#e74c3c', '#2ecc71', '#9b59b6'])\n",
        "        ax.set_title('Model Comparison for Duplicate Detection')\n",
        "        ax.set_ylabel('Accuracy')\n",
        "        ax.set_ylim(0, 1)\n",
        "        ax.set_xticklabels(results.keys(), rotation=45, ha='right')\n",
        "        ax.grid(True, axis='y', alpha=0.3)\n",
        "\n",
        "        for bar, val in zip(bars, results.values()):\n",
        "            ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.02,\n",
        "                    f'{val:.2f}', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "\n",
        "class CombinedDuplicateRemover:\n",
        "    def __init__(self, similarity_threshold=0.9):\n",
        "        self.similarity_threshold = similarity_threshold\n",
        "        self.text_remover = TextDuplicateRemover(n_clusters=10, similarity_threshold=similarity_threshold)\n",
        "        self.tabular_remover = TabularDuplicateRemover(similarity_threshold=similarity_threshold)\n",
        "        self.classification_detector = ClassificationDuplicateDetector()\n",
        "\n",
        "    def analyze_dataset(self, df, text_columns=None, numeric_columns=None):\n",
        "        \"\"\"\n",
        "        Analyze entire dataset for duplicates\n",
        "        \"\"\"\n",
        "        analysis = {\n",
        "            'total_rows': len(df),\n",
        "            'exact_duplicates': 0,\n",
        "            'text_duplicates': 0,\n",
        "            'near_duplicates_kmeans': 0,\n",
        "            'near_duplicates_knn': 0,\n",
        "            'classification_duplicates': 0,\n",
        "            'duplicate_details': {}\n",
        "        }\n",
        "\n",
        "        if df.empty:\n",
        "            return analysis\n",
        "\n",
        "        exact_groups = self.tabular_remover.find_exact_duplicates(df)\n",
        "        analysis['exact_duplicates'] = len(exact_groups)\n",
        "        analysis['duplicate_details']['exact'] = exact_groups\n",
        "\n",
        "        if text_columns:\n",
        "            for col in text_columns:\n",
        "                if col in df.columns:\n",
        "                    self.text_remover.n_clusters = min(10, len(df))\n",
        "                    text_groups = self.text_remover.find_duplicates(df[col].tolist())\n",
        "                    analysis['text_duplicates'] += len(text_groups)\n",
        "                    analysis['duplicate_details'][f'text_{col}'] = text_groups\n",
        "\n",
        "        if numeric_columns:\n",
        "            near_groups_kmeans = self.tabular_remover.find_near_duplicates_kmeans(df, numeric_columns)\n",
        "            analysis['near_duplicates_kmeans'] = len(near_groups_kmeans)\n",
        "            analysis['duplicate_details']['near_kmeans'] = near_groups_kmeans\n",
        "\n",
        "            near_groups_knn = self.tabular_remover.find_near_duplicates_knn(df, numeric_columns)\n",
        "            analysis['near_duplicates_knn'] = len(near_groups_knn)\n",
        "            analysis['duplicate_details']['near_knn'] = near_groups_knn\n",
        "\n",
        "            training_data = self.classification_detector.create_training_data(df, numeric_columns)\n",
        "            if training_data[0] is not None:\n",
        "                self.classification_detector.train_model(*training_data)\n",
        "                class_groups = self.classification_detector.find_duplicates(df, numeric_columns)\n",
        "                analysis['classification_duplicates'] = len(class_groups)\n",
        "                analysis['duplicate_details']['classification'] = class_groups\n",
        "\n",
        "        return analysis\n",
        "\n",
        "    def clean_dataset(self, df, text_columns=None, numeric_columns=None, method='kmeans'):\n",
        "        \"\"\"\n",
        "        Clean dataset by removing duplicates\n",
        "        \"\"\"\n",
        "        if df.empty:\n",
        "            return df, 0\n",
        "\n",
        "        cleaned_df = df.copy()\n",
        "        removed_count = 0\n",
        "\n",
        "        exact_groups = self.tabular_remover.find_exact_duplicates(cleaned_df)\n",
        "        indices_to_remove = []\n",
        "        for group in exact_groups:\n",
        "            indices_to_remove.extend(group[1:])\n",
        "\n",
        "        if indices_to_remove:\n",
        "            cleaned_df = cleaned_df.drop(indices_to_remove).reset_index(drop=True)\n",
        "            removed_count += len(indices_to_remove)\n",
        "\n",
        "        if numeric_columns and method and len(cleaned_df) > 1:\n",
        "            if method == 'kmeans':\n",
        "                near_groups = self.tabular_remover.find_near_duplicates_kmeans(cleaned_df, numeric_columns)\n",
        "            elif method == 'knn':\n",
        "                near_groups = self.tabular_remover.find_near_duplicates_knn(cleaned_df, numeric_columns)\n",
        "            elif method == 'classification':\n",
        "                training_data = self.classification_detector.create_training_data(cleaned_df, numeric_columns)\n",
        "                if training_data[0] is not None:\n",
        "                    self.classification_detector.train_model(*training_data)\n",
        "                    near_groups = self.classification_detector.find_duplicates(cleaned_df, numeric_columns)\n",
        "                else:\n",
        "                    near_groups = []\n",
        "            else:\n",
        "                near_groups = []\n",
        "\n",
        "            indices_to_remove = []\n",
        "            for group in near_groups:\n",
        "                indices_to_remove.extend(group[1:])\n",
        "\n",
        "            if indices_to_remove:\n",
        "                cleaned_df = cleaned_df.drop(indices_to_remove).reset_index(drop=True)\n",
        "                removed_count += len(indices_to_remove)\n",
        "\n",
        "        if text_columns and len(cleaned_df) > 1:\n",
        "            for col in text_columns:\n",
        "                if col in cleaned_df.columns:\n",
        "                    self.text_remover.n_clusters = min(10, len(cleaned_df))\n",
        "                    text_groups = self.text_remover.find_duplicates(cleaned_df[col].tolist())\n",
        "                    indices_to_remove = []\n",
        "                    for group in text_groups:\n",
        "                        indices_to_remove.extend(group[1:])\n",
        "\n",
        "                    if indices_to_remove:\n",
        "                        cleaned_df = cleaned_df.drop(indices_to_remove).reset_index(drop=True)\n",
        "                        removed_count += len(indices_to_remove)\n",
        "\n",
        "        return cleaned_df, removed_count\n",
        "\n",
        "    def generate_report(self, analysis):\n",
        "        \"\"\"\n",
        "        Generate a report of duplicate analysis\n",
        "        \"\"\"\n",
        "        total_duplicates = sum([\n",
        "            analysis['exact_duplicates'],\n",
        "            analysis['text_duplicates'],\n",
        "            analysis['near_duplicates_kmeans'],\n",
        "            analysis['near_duplicates_knn'],\n",
        "            analysis['classification_duplicates']\n",
        "        ])\n",
        "\n",
        "        report = f\"\"\"\n",
        "üìä Dataset Duplicate Analysis Report\n",
        "=====================================\n",
        "\n",
        "Total Rows: {analysis['total_rows']}\n",
        "\n",
        "üîÑ Duplicate Types Found:\n",
        "‚Ä¢ Exact Duplicates: {analysis['exact_duplicates']} groups\n",
        "‚Ä¢ Text Duplicates: {analysis['text_duplicates']} groups\n",
        "‚Ä¢ Near Duplicates (K-means): {analysis['near_duplicates_kmeans']} groups\n",
        "‚Ä¢ Near Duplicates (KNN): {analysis['near_duplicates_knn']} groups\n",
        "‚Ä¢ Classification Duplicates: {analysis['classification_duplicates']} groups\n",
        "\n",
        "üìà Summary:\n",
        "Total Duplicate Groups Found: {total_duplicates}\n",
        "        \"\"\"\n",
        "        return report\n",
        "\n",
        "\n",
        "def fig_to_base64(fig):\n",
        "    \"\"\"Convert matplotlib figure to base64 string\"\"\"\n",
        "    if fig is None:\n",
        "        return None\n",
        "    buf = io.BytesIO()\n",
        "    fig.savefig(buf, format='png', bbox_inches='tight', dpi=100)\n",
        "    buf.seek(0)\n",
        "    img_base64 = base64.b64encode(buf.read()).decode('utf-8')\n",
        "    buf.close()\n",
        "    plt.close(fig)\n",
        "    return img_base64"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing duplicate_remover_core.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CELL 4: Create Streamlit Application\n",
        "# =============================================================================\n",
        "%%writefile streamlit_app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import sys\n",
        "\n",
        "# Import core functionality\n",
        "from duplicate_remover_core import (\n",
        "    TextDuplicateRemover,\n",
        "    TabularDuplicateRemover,\n",
        "    ClassificationDuplicateDetector,\n",
        "    CombinedDuplicateRemover\n",
        ")\n",
        "\n",
        "# Page configuration\n",
        "st.set_page_config(\n",
        "    page_title=\"üîç Duplicate Remover Tool\",\n",
        "    page_icon=\"üîç\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "# Custom CSS\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "    .main-header {\n",
        "        font-size: 2.5rem;\n",
        "        font-weight: bold;\n",
        "        color: #1f77b4;\n",
        "        text-align: center;\n",
        "        margin-bottom: 2rem;\n",
        "    }\n",
        "    .sub-header {\n",
        "        font-size: 1.5rem;\n",
        "        color: #2c3e50;\n",
        "        margin-top: 1.5rem;\n",
        "        margin-bottom: 1rem;\n",
        "    }\n",
        "    .metric-card {\n",
        "        background-color: #f8f9fa;\n",
        "        border-radius: 10px;\n",
        "        padding: 1rem;\n",
        "        box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
        "    }\n",
        "    .success-box {\n",
        "        background-color: #d4edda;\n",
        "        border: 1px solid #c3e6cb;\n",
        "        border-radius: 5px;\n",
        "        padding: 1rem;\n",
        "        color: #155724;\n",
        "    }\n",
        "    .warning-box {\n",
        "        background-color: #fff3cd;\n",
        "        border: 1px solid #ffeeba;\n",
        "        border-radius: 5px;\n",
        "        padding: 1rem;\n",
        "        color: #856404;\n",
        "    }\n",
        "    .info-box {\n",
        "        background-color: #d1ecf1;\n",
        "        border: 1px solid #bee5eb;\n",
        "        border-radius: 5px;\n",
        "        padding: 1rem;\n",
        "        color: #0c5460;\n",
        "    }\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "def main():\n",
        "    st.markdown('<h1 class=\"main-header\">üîç Duplicate Remover Tool</h1>', unsafe_allow_html=True)\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # Sidebar\n",
        "    with st.sidebar:\n",
        "        st.header(\"‚öôÔ∏è Settings\")\n",
        "\n",
        "        similarity_threshold = st.slider(\n",
        "            \"Similarity Threshold\",\n",
        "            min_value=0.5,\n",
        "            max_value=1.0,\n",
        "            value=0.9,\n",
        "            step=0.05,\n",
        "            help=\"Higher values mean stricter duplicate detection\"\n",
        "        )\n",
        "\n",
        "        n_clusters = st.slider(\n",
        "            \"Number of Clusters (for K-means)\",\n",
        "            min_value=2,\n",
        "            max_value=20,\n",
        "            value=10,\n",
        "            help=\"Number of clusters for K-means algorithm\"\n",
        "        )\n",
        "\n",
        "        detection_method = st.selectbox(\n",
        "            \"Detection Method\",\n",
        "            options=[\"K-means\", \"KNN\", \"Classification\", \"All Methods\"],\n",
        "            help=\"Select the duplicate detection method\"\n",
        "        )\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.header(\"üìñ About\")\n",
        "        st.info(\"\"\"\n",
        "        This tool helps you find and remove duplicate data using various machine learning techniques:\n",
        "\n",
        "        - **Exact Duplicates**: Identical rows\n",
        "        - **Text Duplicates**: Similar text content\n",
        "        - **Near Duplicates (K-means)**: Clustering-based detection\n",
        "        - **Near Duplicates (KNN)**: Nearest neighbor detection\n",
        "        - **Classification**: ML-based detection\n",
        "        \"\"\")\n",
        "\n",
        "    # Main content tabs\n",
        "    tab1, tab2, tab3, tab4 = st.tabs([\"üì§ Upload Data\", \"üîç Analyze\", \"üßπ Clean Data\", \"üìä Visualize\"])\n",
        "\n",
        "    # Session state initialization\n",
        "    if 'df' not in st.session_state:\n",
        "        st.session_state.df = None\n",
        "    if 'analysis' not in st.session_state:\n",
        "        st.session_state.analysis = None\n",
        "    if 'cleaned_df' not in st.session_state:\n",
        "        st.session_state.cleaned_df = None\n",
        "\n",
        "    # Tab 1: Upload Data\n",
        "    with tab1:\n",
        "        st.markdown('<h2 class=\"sub-header\">üì§ Upload Your Dataset</h2>', unsafe_allow_html=True)\n",
        "\n",
        "        col1, col2 = st.columns([2, 1])\n",
        "\n",
        "        with col1:\n",
        "            uploaded_file = st.file_uploader(\n",
        "                \"Choose a CSV file\",\n",
        "                type=['csv'],\n",
        "                help=\"Upload a CSV file to analyze for duplicates\"\n",
        "            )\n",
        "\n",
        "            if uploaded_file is not None:\n",
        "                try:\n",
        "                    df = pd.read_csv(uploaded_file)\n",
        "                    st.session_state.df = df\n",
        "                    st.success(f\"‚úÖ Successfully loaded {len(df)} rows and {len(df.columns)} columns!\")\n",
        "                except Exception as e:\n",
        "                    st.error(f\"‚ùå Error loading file: {str(e)}\")\n",
        "\n",
        "        with col2:\n",
        "            st.markdown(\"### Or use sample data\")\n",
        "            if st.button(\"üìä Load Sample Data\", use_container_width=True):\n",
        "                sample_data = {\n",
        "                    'Name': ['John', 'Jane', 'John', 'Bob', 'Jane', 'Alice', 'Charlie', 'John'],\n",
        "                    'Age': [25, 30, 25, 35, 30, 28, 40, 25],\n",
        "                    'City': ['NYC', 'LA', 'NYC', 'Chicago', 'LA', 'Boston', 'Seattle', 'NYC'],\n",
        "                    'Salary': [50000, 60000, 50000, 70000, 60000, 55000, 80000, 50000],\n",
        "                    'Department': ['IT', 'HR', 'IT', 'Finance', 'HR', 'Marketing', 'IT', 'IT']\n",
        "                }\n",
        "                st.session_state.df = pd.DataFrame(sample_data)\n",
        "                st.success(\"‚úÖ Sample data loaded!\")\n",
        "\n",
        "        if st.session_state.df is not None:\n",
        "            st.markdown(\"### üìã Data Preview\")\n",
        "            st.dataframe(st.session_state.df.head(20), use_container_width=True)\n",
        "\n",
        "            col1, col2, col3 = st.columns(3)\n",
        "            with col1:\n",
        "                st.metric(\"Total Rows\", len(st.session_state.df))\n",
        "            with col2:\n",
        "                st.metric(\"Total Columns\", len(st.session_state.df.columns))\n",
        "            with col3:\n",
        "                st.metric(\"Memory Usage\", f\"{st.session_state.df.memory_usage(deep=True).sum() / 1024:.2f} KB\")\n",
        "\n",
        "            st.markdown(\"### üìä Column Information\")\n",
        "            col_info = pd.DataFrame({\n",
        "                'Column': st.session_state.df.columns,\n",
        "                'Type': st.session_state.df.dtypes.astype(str),\n",
        "                'Non-Null Count': st.session_state.df.count().values,\n",
        "                'Unique Values': st.session_state.df.nunique().values\n",
        "            })\n",
        "            st.dataframe(col_info, use_container_width=True)\n",
        "\n",
        "    # Tab 2: Analyze\n",
        "    with tab2:\n",
        "        st.markdown('<h2 class=\"sub-header\">üîç Analyze Duplicates</h2>', unsafe_allow_html=True)\n",
        "\n",
        "        if st.session_state.df is None:\n",
        "            st.warning(\"‚ö†Ô∏è Please upload a dataset first!\")\n",
        "        else:\n",
        "            df = st.session_state.df\n",
        "\n",
        "            col1, col2 = st.columns(2)\n",
        "\n",
        "            with col1:\n",
        "                text_columns = st.multiselect(\n",
        "                    \"Select Text Columns\",\n",
        "                    options=df.select_dtypes(include=['object']).columns.tolist(),\n",
        "                    help=\"Select columns containing text data\"\n",
        "                )\n",
        "\n",
        "            with col2:\n",
        "                numeric_columns = st.multiselect(\n",
        "                    \"Select Numeric Columns\",\n",
        "                    options=df.select_dtypes(include=[np.number]).columns.tolist(),\n",
        "                    default=df.select_dtypes(include=[np.number]).columns.tolist(),\n",
        "                    help=\"Select columns containing numeric data\"\n",
        "                )\n",
        "\n",
        "            if st.button(\"üîç Analyze Dataset\", type=\"primary\", use_container_width=True):\n",
        "                with st.spinner(\"Analyzing dataset for duplicates...\"):\n",
        "                    remover = CombinedDuplicateRemover(similarity_threshold=similarity_threshold)\n",
        "                    remover.text_remover.n_clusters = min(n_clusters, len(df))\n",
        "\n",
        "                    analysis = remover.analyze_dataset(\n",
        "                        df,\n",
        "                        text_columns=text_columns if text_columns else None,\n",
        "                        numeric_columns=numeric_columns if numeric_columns else None\n",
        "                    )\n",
        "                    st.session_state.analysis = analysis\n",
        "\n",
        "                    st.success(\"‚úÖ Analysis complete!\")\n",
        "\n",
        "            if st.session_state.analysis is not None:\n",
        "                analysis = st.session_state.analysis\n",
        "\n",
        "                st.markdown(\"### üìä Analysis Results\")\n",
        "\n",
        "                col1, col2, col3, col4, col5 = st.columns(5)\n",
        "                with col1:\n",
        "                    st.metric(\"Exact Duplicates\", analysis['exact_duplicates'])\n",
        "                with col2:\n",
        "                    st.metric(\"Text Duplicates\", analysis['text_duplicates'])\n",
        "                with col3:\n",
        "                    st.metric(\"K-means Duplicates\", analysis['near_duplicates_kmeans'])\n",
        "                with col4:\n",
        "                    st.metric(\"KNN Duplicates\", analysis['near_duplicates_knn'])\n",
        "                with col5:\n",
        "                    st.metric(\"Classification Duplicates\", analysis['classification_duplicates'])\n",
        "\n",
        "                remover = CombinedDuplicateRemover()\n",
        "                st.markdown(\"### üìù Detailed Report\")\n",
        "                st.text(remover.generate_report(analysis))\n",
        "\n",
        "                if analysis['duplicate_details'].get('exact'):\n",
        "                    st.markdown(\"### üîÑ Exact Duplicate Groups\")\n",
        "                    for i, group in enumerate(analysis['duplicate_details']['exact'][:5]):\n",
        "                        with st.expander(f\"Group {i + 1} ({len(group)} rows)\"):\n",
        "                            st.dataframe(df.iloc[group], use_container_width=True)\n",
        "\n",
        "    # Tab 3: Clean Data\n",
        "    with tab3:\n",
        "        st.markdown('<h2 class=\"sub-header\">üßπ Clean Dataset</h2>', unsafe_allow_html=True)\n",
        "\n",
        "        if st.session_state.df is None:\n",
        "            st.warning(\"‚ö†Ô∏è Please upload a dataset first!\")\n",
        "        else:\n",
        "            df = st.session_state.df\n",
        "\n",
        "            col1, col2 = st.columns(2)\n",
        "\n",
        "            with col1:\n",
        "                clean_text_columns = st.multiselect(\n",
        "                    \"Text Columns to Clean\",\n",
        "                    options=df.select_dtypes(include=['object']).columns.tolist(),\n",
        "                    key=\"clean_text\"\n",
        "                )\n",
        "\n",
        "            with col2:\n",
        "                clean_numeric_columns = st.multiselect(\n",
        "                    \"Numeric Columns to Clean\",\n",
        "                    options=df.select_dtypes(include=[np.number]).columns.tolist(),\n",
        "                    default=df.select_dtypes(include=[np.number]).columns.tolist(),\n",
        "                    key=\"clean_numeric\"\n",
        "                )\n",
        "\n",
        "            method_map = {\n",
        "                \"K-means\": \"kmeans\",\n",
        "                \"KNN\": \"knn\",\n",
        "                \"Classification\": \"classification\"\n",
        "            }\n",
        "            clean_method = method_map.get(detection_method, \"kmeans\")\n",
        "\n",
        "            if st.button(\"üßπ Clean Dataset\", type=\"primary\", use_container_width=True):\n",
        "                with st.spinner(\"Cleaning dataset...\"):\n",
        "                    remover = CombinedDuplicateRemover(similarity_threshold=similarity_threshold)\n",
        "                    remover.text_remover.n_clusters = min(n_clusters, len(df))\n",
        "\n",
        "                    cleaned_df, removed_count = remover.clean_dataset(\n",
        "                        df,\n",
        "                        text_columns=clean_text_columns if clean_text_columns else None,\n",
        "                        numeric_columns=clean_numeric_columns if clean_numeric_columns else None,\n",
        "                        method=clean_method\n",
        "                    )\n",
        "                    st.session_state.cleaned_df = cleaned_df\n",
        "\n",
        "                    st.success(f\"‚úÖ Cleaning complete! Removed {removed_count} duplicate entries.\")\n",
        "\n",
        "            if st.session_state.cleaned_df is not None:\n",
        "                cleaned_df = st.session_state.cleaned_df\n",
        "\n",
        "                col1, col2 = st.columns(2)\n",
        "                with col1:\n",
        "                    st.metric(\"Original Rows\", len(df))\n",
        "                with col2:\n",
        "                    st.metric(\"Cleaned Rows\", len(cleaned_df))\n",
        "\n",
        "                st.markdown(\"### üìã Cleaned Data Preview\")\n",
        "                st.dataframe(cleaned_df.head(20), use_container_width=True)\n",
        "\n",
        "                csv = cleaned_df.to_csv(index=False)\n",
        "                st.download_button(\n",
        "                    label=\"üì• Download Cleaned Dataset\",\n",
        "                    data=csv,\n",
        "                    file_name=\"cleaned_dataset.csv\",\n",
        "                    mime=\"text/csv\",\n",
        "                    use_container_width=True\n",
        "                )\n",
        "\n",
        "    # Tab 4: Visualize\n",
        "    with tab4:\n",
        "        st.markdown('<h2 class=\"sub-header\">üìä Visualizations</h2>', unsafe_allow_html=True)\n",
        "\n",
        "        if st.session_state.df is None:\n",
        "            st.warning(\"‚ö†Ô∏è Please upload a dataset first!\")\n",
        "        else:\n",
        "            df = st.session_state.df\n",
        "            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "            if len(numeric_cols) >= 2:\n",
        "                col1, col2 = st.columns(2)\n",
        "\n",
        "                with col1:\n",
        "                    if st.button(\"üìä Show Cluster Visualization\", use_container_width=True):\n",
        "                        with st.spinner(\"Generating cluster visualization...\"):\n",
        "                            tabular_remover = TabularDuplicateRemover(similarity_threshold=similarity_threshold)\n",
        "                            fig = tabular_remover.visualize_clusters(df, numeric_cols)\n",
        "                            if fig:\n",
        "                                st.pyplot(fig)\n",
        "                                plt.close(fig)\n",
        "                            else:\n",
        "                                st.warning(\"Could not generate visualization with current data.\")\n",
        "\n",
        "                with col2:\n",
        "                    if st.button(\"üìà Compare ML Models\", use_container_width=True):\n",
        "                        with st.spinner(\"Comparing models...\"):\n",
        "                            detector = ClassificationDuplicateDetector()\n",
        "                            results = detector.compare_models(df, numeric_cols)\n",
        "                            if results:\n",
        "                                fig = detector.plot_model_comparison(results)\n",
        "                                if fig:\n",
        "                                    st.pyplot(fig)\n",
        "                                    plt.close(fig)\n",
        "\n",
        "                                st.markdown(\"### Model Accuracy Results\")\n",
        "                                results_df = pd.DataFrame({\n",
        "                                    'Model': results.keys(),\n",
        "                                    'Accuracy': results.values()\n",
        "                                })\n",
        "                                st.dataframe(results_df, use_container_width=True)\n",
        "                            else:\n",
        "                                st.warning(\"Could not compare models with current data.\")\n",
        "\n",
        "                st.markdown(\"### üìä Data Distribution\")\n",
        "                selected_col = st.selectbox(\"Select column to visualize\", numeric_cols)\n",
        "                fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "                axes[0].hist(df[selected_col].dropna(), bins=30, edgecolor='black', alpha=0.7)\n",
        "                axes[0].set_title(f'Distribution of {selected_col}')\n",
        "                axes[0].set_xlabel(selected_col)\n",
        "                axes[0].set_ylabel('Frequency')\n",
        "\n",
        "                axes[1].boxplot(df[selected_col].dropna())\n",
        "                axes[1].set_title(f'Box Plot of {selected_col}')\n",
        "                axes[1].set_ylabel(selected_col)\n",
        "\n",
        "                plt.tight_layout()\n",
        "                st.pyplot(fig)\n",
        "                plt.close(fig)\n",
        "            else:\n",
        "                st.warning(\"Need at least 2 numeric columns for visualizations.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCQTJwZN5r6P",
        "outputId": "af9362fb-463d-4ce5-e00f-f0c3cfb01314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CELL 5: Create Flask Application\n",
        "# =============================================================================\n",
        "%%writefile flask_app.py\n",
        "\n",
        "from flask import Flask, render_template_string, request, jsonify, send_file\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import base64\n",
        "import json\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from duplicate_remover_core import (\n",
        "    TextDuplicateRemover,\n",
        "    TabularDuplicateRemover,\n",
        "    ClassificationDuplicateDetector,\n",
        "    CombinedDuplicateRemover,\n",
        "    fig_to_base64\n",
        ")\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Store data in memory\n",
        "app_data = {\n",
        "    'df': None,\n",
        "    'analysis': None,\n",
        "    'cleaned_df': None\n",
        "}\n",
        "\n",
        "HTML_TEMPLATE = '''\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>üîç Duplicate Remover Tool</title>\n",
        "    <link href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css\" rel=\"stylesheet\">\n",
        "    <link href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css\" rel=\"stylesheet\">\n",
        "    <style>\n",
        "        :root {\n",
        "            --primary-color: #3498db;\n",
        "            --secondary-color: #2ecc71;\n",
        "            --accent-color: #9b59b6;\n",
        "            --background-color: #f8f9fa;\n",
        "            --card-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n",
        "        }\n",
        "        body {\n",
        "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "            min-height: 100vh;\n",
        "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
        "        }\n",
        "        .main-container {\n",
        "            background: rgba(255, 255, 255, 0.95);\n",
        "            border-radius: 20px;\n",
        "            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);\n",
        "            margin: 20px auto;\n",
        "            max-width: 1400px;\n",
        "            padding: 30px;\n",
        "        }\n",
        "        .header {\n",
        "            text-align: center;\n",
        "            margin-bottom: 30px;\n",
        "            padding: 20px;\n",
        "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "            border-radius: 15px;\n",
        "            color: white;\n",
        "        }\n",
        "        .header h1 {\n",
        "            font-size: 2.5rem;\n",
        "            font-weight: bold;\n",
        "            margin-bottom: 10px;\n",
        "        }\n",
        "        .header p {\n",
        "            font-size: 1.1rem;\n",
        "            opacity: 0.9;\n",
        "        }\n",
        "        .card {\n",
        "            border: none;\n",
        "            border-radius: 15px;\n",
        "            box-shadow: var(--card-shadow);\n",
        "            margin-bottom: 20px;\n",
        "            transition: transform 0.3s ease, box-shadow 0.3s ease;\n",
        "        }\n",
        "        .card:hover {\n",
        "            transform: translateY(-5px);\n",
        "            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.15);\n",
        "        }\n",
        "        .card-header {\n",
        "            background: linear-gradient(135deg, var(--primary-color), var(--accent-color));\n",
        "            color: white;\n",
        "            border-radius: 15px 15px 0 0 !important;\n",
        "            font-weight: bold;\n",
        "            padding: 15px 20px;\n",
        "        }\n",
        "        .metric-card {\n",
        "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "            color: white;\n",
        "            border-radius: 15px;\n",
        "            padding: 20px;\n",
        "            text-align: center;\n",
        "            margin-bottom: 15px;\n",
        "        }\n",
        "        .metric-card h3 {\n",
        "            font-size: 2rem;\n",
        "            font-weight: bold;\n",
        "            margin-bottom: 5px;\n",
        "        }\n",
        "        .metric-card p {\n",
        "            margin: 0;\n",
        "            opacity: 0.9;\n",
        "        }\n",
        "        .btn-primary {\n",
        "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "            border: none;\n",
        "            border-radius: 10px;\n",
        "            padding: 12px 30px;\n",
        "            font-weight: bold;\n",
        "            transition: transform 0.3s ease, box-shadow 0.3s ease;\n",
        "        }\n",
        "        .btn-primary:hover {\n",
        "            transform: translateY(-2px);\n",
        "            box-shadow: 0 5px 20px rgba(102, 126, 234, 0.4);\n",
        "            background: linear-gradient(135deg, #764ba2 0%, #667eea 100%);\n",
        "        }\n",
        "        .btn-success {\n",
        "            background: linear-gradient(135deg, #2ecc71 0%, #27ae60 100%);\n",
        "            border: none;\n",
        "            border-radius: 10px;\n",
        "            padding: 12px 30px;\n",
        "            font-weight: bold;\n",
        "        }\n",
        "        .nav-tabs {\n",
        "            border: none;\n",
        "            margin-bottom: 20px;\n",
        "        }\n",
        "        .nav-tabs .nav-link {\n",
        "            border: none;\n",
        "            border-radius: 10px;\n",
        "            padding: 15px 25px;\n",
        "            margin-right: 10px;\n",
        "            background: #e9ecef;\n",
        "            color: #495057;\n",
        "            font-weight: 600;\n",
        "            transition: all 0.3s ease;\n",
        "        }\n",
        "        .nav-tabs .nav-link.active {\n",
        "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "            color: white;\n",
        "        }\n",
        "        .nav-tabs .nav-link:hover:not(.active) {\n",
        "            background: #dee2e6;\n",
        "        }\n",
        "        .table {\n",
        "            border-radius: 10px;\n",
        "            overflow: hidden;\n",
        "        }\n",
        "        .table thead {\n",
        "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "            color: white;\n",
        "        }\n",
        "        .table-striped tbody tr:nth-of-type(odd) {\n",
        "            background-color: rgba(102, 126, 234, 0.05);\n",
        "        }\n",
        "        .form-control, .form-select {\n",
        "            border-radius: 10px;\n",
        "            border: 2px solid #e9ecef;\n",
        "            padding: 12px 15px;\n",
        "            transition: border-color 0.3s ease, box-shadow 0.3s ease;\n",
        "        }\n",
        "        .form-control:focus, .form-select:focus {\n",
        "            border-color: #667eea;\n",
        "            box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.2);\n",
        "        }\n",
        "        .alert {\n",
        "            border-radius: 10px;\n",
        "            border: none;\n",
        "        }\n",
        "        .alert-success {\n",
        "            background: linear-gradient(135deg, rgba(46, 204, 113, 0.2), rgba(39, 174, 96, 0.2));\n",
        "            color: #155724;\n",
        "        }\n",
        "        .alert-warning {\n",
        "            background: linear-gradient(135deg, rgba(241, 196, 15, 0.2), rgba(243, 156, 18, 0.2));\n",
        "            color: #856404;\n",
        "        }\n",
        "        .alert-info {\n",
        "            background: linear-gradient(135deg, rgba(52, 152, 219, 0.2), rgba(41, 128, 185, 0.2));\n",
        "            color: #0c5460;\n",
        "        }\n",
        "        .spinner-border {\n",
        "            width: 3rem;\n",
        "            height: 3rem;\n",
        "        }\n",
        "        .loading-overlay {\n",
        "            position: fixed;\n",
        "            top: 0;\n",
        "            left: 0;\n",
        "            width: 100%;\n",
        "            height: 100%;\n",
        "            background: rgba(255, 255, 255, 0.9);\n",
        "            display: none;\n",
        "            justify-content: center;\n",
        "            align-items: center;\n",
        "            z-index: 9999;\n",
        "            flex-direction: column;\n",
        "        }\n",
        "        .loading-overlay.show {\n",
        "            display: flex;\n",
        "        }\n",
        "        .file-upload {\n",
        "            border: 3px dashed #667eea;\n",
        "            border-radius: 15px;\n",
        "            padding: 40px;\n",
        "            text-align: center;\n",
        "            transition: all 0.3s ease;\n",
        "            cursor: pointer;\n",
        "        }\n",
        "        .file-upload:hover {\n",
        "            border-color: #764ba2;\n",
        "            background: rgba(102, 126, 234, 0.05);\n",
        "        }\n",
        "        .file-upload i {\n",
        "            font-size: 3rem;\n",
        "            color: #667eea;\n",
        "            margin-bottom: 15px;\n",
        "        }\n",
        "        .visualization-container {\n",
        "            background: white;\n",
        "            border-radius: 15px;\n",
        "            padding: 20px;\n",
        "            box-shadow: var(--card-shadow);\n",
        "        }\n",
        "        .visualization-container img {\n",
        "            max-width: 100%;\n",
        "            border-radius: 10px;\n",
        "        }\n",
        "        .report-box {\n",
        "            background: #f8f9fa;\n",
        "            border-radius: 15px;\n",
        "            padding: 20px;\n",
        "            font-family: 'Courier New', monospace;\n",
        "            white-space: pre-wrap;\n",
        "            border-left: 5px solid #667eea;\n",
        "        }\n",
        "        .settings-panel {\n",
        "            background: linear-gradient(135deg, rgba(102, 126, 234, 0.1), rgba(118, 75, 162, 0.1));\n",
        "            border-radius: 15px;\n",
        "            padding: 20px;\n",
        "            margin-bottom: 20px;\n",
        "        }\n",
        "        .footer {\n",
        "            text-align: center;\n",
        "            padding: 20px;\n",
        "            color: #6c757d;\n",
        "            margin-top: 30px;\n",
        "        }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"loading-overlay\" id=\"loadingOverlay\">\n",
        "        <div class=\"spinner-border text-primary\" role=\"status\"></div>\n",
        "        <p class=\"mt-3 text-primary fw-bold\">Processing...</p>\n",
        "    </div>\n",
        "\n",
        "    <div class=\"main-container\">\n",
        "        <div class=\"header\">\n",
        "            <h1><i class=\"fas fa-search\"></i> Duplicate Remover Tool</h1>\n",
        "            <p>Find and remove duplicate data using Machine Learning techniques</p>\n",
        "        </div>\n",
        "\n",
        "        <ul class=\"nav nav-tabs\" id=\"mainTabs\" role=\"tablist\">\n",
        "            <li class=\"nav-item\" role=\"presentation\">\n",
        "                <button class=\"nav-link active\" id=\"upload-tab\" data-bs-toggle=\"tab\" data-bs-target=\"#upload\" type=\"button\" role=\"tab\">\n",
        "                    <i class=\"fas fa-upload me-2\"></i>Upload Data\n",
        "                </button>\n",
        "            </li>\n",
        "            <li class=\"nav-item\" role=\"presentation\">\n",
        "                <button class=\"nav-link\" id=\"analyze-tab\" data-bs-toggle=\"tab\" data-bs-target=\"#analyze\" type=\"button\" role=\"tab\">\n",
        "                    <i class=\"fas fa-search me-2\"></i>Analyze\n",
        "                </button>\n",
        "            </li>\n",
        "            <li class=\"nav-item\" role=\"presentation\">\n",
        "                <button class=\"nav-link\" id=\"clean-tab\" data-bs-toggle=\"tab\" data-bs-target=\"#clean\" type=\"button\" role=\"tab\">\n",
        "                    <i class=\"fas fa-broom me-2\"></i>Clean Data\n",
        "                </button>\n",
        "            </li>\n",
        "            <li class=\"nav-item\" role=\"presentation\">\n",
        "                <button class=\"nav-link\" id=\"visualize-tab\" data-bs-toggle=\"tab\" data-bs-target=\"#visualize\" type=\"button\" role=\"tab\">\n",
        "                    <i class=\"fas fa-chart-bar me-2\"></i>Visualize\n",
        "                </button>\n",
        "            </li>\n",
        "        </ul>\n",
        "\n",
        "        <div class=\"tab-content\" id=\"mainTabsContent\">\n",
        "            <!-- Upload Tab -->\n",
        "            <div class=\"tab-pane fade show active\" id=\"upload\" role=\"tabpanel\">\n",
        "                <div class=\"row\">\n",
        "                    <div class=\"col-md-8\">\n",
        "                        <div class=\"card\">\n",
        "                            <div class=\"card-header\">\n",
        "                                <i class=\"fas fa-file-csv me-2\"></i>Upload Dataset\n",
        "                            </div>\n",
        "                            <div class=\"card-body\">\n",
        "                                <form id=\"uploadForm\" enctype=\"multipart/form-data\">\n",
        "                                    <div class=\"file-upload\" onclick=\"document.getElementById('fileInput').click()\">\n",
        "                                        <i class=\"fas fa-cloud-upload-alt\"></i>\n",
        "                                        <h4>Drop your CSV file here</h4>\n",
        "                                        <p class=\"text-muted\">or click to browse</p>\n",
        "                                        <input type=\"file\" id=\"fileInput\" name=\"file\" accept=\".csv\" style=\"display: none;\">\n",
        "                                    </div>\n",
        "                                    <div id=\"fileName\" class=\"mt-3 text-center\"></div>\n",
        "                                    <button type=\"submit\" class=\"btn btn-primary w-100 mt-3\">\n",
        "                                        <i class=\"fas fa-upload me-2\"></i>Upload File\n",
        "                                    </button>\n",
        "                                </form>\n",
        "                            </div>\n",
        "                        </div>\n",
        "                    </div>\n",
        "                    <div class=\"col-md-4\">\n",
        "                        <div class=\"card\">\n",
        "                            <div class=\"card-header\">\n",
        "                                <i class=\"fas fa-database me-2\"></i>Sample Data\n",
        "                            </div>\n",
        "                            <div class=\"card-body\">\n",
        "                                <p>Don't have a dataset? Try our sample data!</p>\n",
        "                                <button class=\"btn btn-success w-100\" onclick=\"loadSampleData()\">\n",
        "                                    <i class=\"fas fa-table me-2\"></i>Load Sample Data\n",
        "                                </button>\n",
        "                            </div>\n",
        "                        </div>\n",
        "                        <div class=\"card\">\n",
        "                            <div class=\"card-header\">\n",
        "                                <i class=\"fas fa-info-circle me-2\"></i>Info\n",
        "                            </div>\n",
        "                            <div class=\"card-body\">\n",
        "                                <div id=\"dataInfo\">\n",
        "                                    <p class=\"text-muted\">No data loaded yet.</p>\n",
        "                                </div>\n",
        "                            </div>\n",
        "                        </div>\n",
        "                    </div>\n",
        "                </div>\n",
        "                <div id=\"dataPreview\" class=\"mt-4\" style=\"display: none;\">\n",
        "                    <div class=\"card\">\n",
        "                        <div class=\"card-header\">\n",
        "                            <i class=\"fas fa-table me-2\"></i>Data Preview\n",
        "                        </div>\n",
        "                        <div class=\"card-body\">\n",
        "                            <div class=\"table-responsive\" id=\"previewTable\"></div>\n",
        "                        </div>\n",
        "                    </div>\n",
        "                </div>\n",
        "            </div>\n",
        "\n",
        "            <!-- Analyze Tab -->\n",
        "            <div class=\"tab-pane fade\" id=\"analyze\" role=\"tabpanel\">\n",
        "                <div class=\"settings-panel\">\n",
        "                    <h5><i class=\"fas fa-cog me-2\"></i>Analysis Settings</h5>\n",
        "                    <div class=\"row\">\n",
        "                        <div class=\"col-md-3\">\n",
        "                            <label class=\"form-label\">Similarity Threshold</label>\n",
        "                            <input type=\"range\" class=\"form-range\" id=\"similarityThreshold\" min=\"0.5\" max=\"1\" step=\"0.05\" value=\"0.9\">\n",
        "                            <span id=\"thresholdValue\">0.9</span>\n",
        "                        </div>\n",
        "                        <div class=\"col-md-3\">\n",
        "                            <label class=\"form-label\">Number of Clusters</label>\n",
        "                            <input type=\"number\" class=\"form-control\" id=\"nClusters\" min=\"2\" max=\"20\" value=\"10\">\n",
        "                        </div>\n",
        "                        <div class=\"col-md-3\">\n",
        "                            <label class=\"form-label\">Text Columns</label>\n",
        "                            <select class=\"form-select\" id=\"textColumns\" multiple></select>\n",
        "                        </div>\n",
        "                        <div class=\"col-md-3\">\n",
        "                            <label class=\"form-label\">Numeric Columns</label>\n",
        "                            <select class=\"form-select\" id=\"numericColumns\" multiple></select>\n",
        "                        </div>\n",
        "                    </div>\n",
        "                </div>\n",
        "                <button class=\"btn btn-primary mb-4\" onclick=\"analyzeData()\">\n",
        "                    <i class=\"fas fa-search me-2\"></i>Analyze Dataset\n",
        "                </button>\n",
        "                <div id=\"analysisResults\"></div>\n",
        "            </div>\n",
        "\n",
        "            <!-- Clean Tab -->\n",
        "            <div class=\"tab-pane fade\" id=\"clean\" role=\"tabpanel\">\n",
        "                <div class=\"settings-panel\">\n",
        "                    <h5><i class=\"fas fa-cog me-2\"></i>Cleaning Settings</h5>\n",
        "                    <div class=\"row\">\n",
        "                        <div class=\"col-md-4\">\n",
        "                            <label class=\"form-label\">Detection Method</label>\n",
        "                            <select class=\"form-select\" id=\"cleanMethod\">\n",
        "                                <option value=\"kmeans\">K-means Clustering</option>\n",
        "                                <option value=\"knn\">K-Nearest Neighbors</option>\n",
        "                                <option value=\"classification\">Classification</option>\n",
        "                            </select>\n",
        "                        </div>\n",
        "                        <div class=\"col-md-4\">\n",
        "                            <label class=\"form-label\">Text Columns to Clean</label>\n",
        "                            <select class=\"form-select\" id=\"cleanTextColumns\" multiple></select>\n",
        "                        </div>\n",
        "                        <div class=\"col-md-4\">\n",
        "                            <label class=\"form-label\">Numeric Columns to Clean</label>\n",
        "                            <select class=\"form-select\" id=\"cleanNumericColumns\" multiple></select>\n",
        "                        </div>\n",
        "                    </div>\n",
        "                </div>\n",
        "                <button class=\"btn btn-success mb-4\" onclick=\"cleanData()\">\n",
        "                    <i class=\"fas fa-broom me-2\"></i>Clean Dataset\n",
        "                </button>\n",
        "                <div id=\"cleanResults\"></div>\n",
        "            </div>\n",
        "\n",
        "            <!-- Visualize Tab -->\n",
        "            <div class=\"tab-pane fade\" id=\"visualize\" role=\"tabpanel\">\n",
        "                <div class=\"row\">\n",
        "                    <div class=\"col-md-6\">\n",
        "                        <button class=\"btn btn-primary w-100 mb-3\" onclick=\"showClusterVisualization()\">\n",
        "                            <i class=\"fas fa-project-diagram me-2\"></i>Show Cluster Visualization\n",
        "                        </button>\n",
        "                        <div id=\"clusterViz\" class=\"visualization-container\"></div>\n",
        "                    </div>\n",
        "                    <div class=\"col-md-6\">\n",
        "                        <button class=\"btn btn-primary w-100 mb-3\" onclick=\"compareModels()\">\n",
        "                            <i class=\"fas fa-chart-bar me-2\"></i>Compare ML Models\n",
        "                        </button>\n",
        "                        <div id=\"modelComparison\" class=\"visualization-container\"></div>\n",
        "                    </div>\n",
        "                </div>\n",
        "            </div>\n",
        "        </div>\n",
        "\n",
        "        <div class=\"footer\">\n",
        "            <p><i class=\"fas fa-code me-2\"></i>Duplicate Remover Tool | Built with Flask & Machine Learning</p>\n",
        "        </div>\n",
        "    </div>\n",
        "\n",
        "    <script src=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js\"></script>\n",
        "    <script>\n",
        "        // File input handling\n",
        "        document.getElementById('fileInput').addEventListener('change', function(e) {\n",
        "            var fileName = e.target.files[0] ? e.target.files[0].name : '';\n",
        "            document.getElementById('fileName').innerHTML = fileName ?\n",
        "                '<span class=\"badge bg-success\"><i class=\"fas fa-check me-2\"></i>' + fileName + '</span>' : '';\n",
        "        });\n",
        "\n",
        "        // Slider value display\n",
        "        document.getElementById('similarityThreshold').addEventListener('input', function(e) {\n",
        "            document.getElementById('thresholdValue').textContent = e.target.value;\n",
        "        });\n",
        "\n",
        "        // Show loading overlay\n",
        "        function showLoading() {\n",
        "            document.getElementById('loadingOverlay').classList.add('show');\n",
        "        }\n",
        "\n",
        "        // Hide loading overlay\n",
        "        function hideLoading() {\n",
        "            document.getElementById('loadingOverlay').classList.remove('show');\n",
        "        }\n",
        "\n",
        "        // Upload form handling\n",
        "        document.getElementById('uploadForm').addEventListener('submit', function(e) {\n",
        "            e.preventDefault();\n",
        "            var formData = new FormData();\n",
        "            var fileInput = document.getElementById('fileInput');\n",
        "\n",
        "            if (!fileInput.files[0]) {\n",
        "                alert('Please select a file first!');\n",
        "                return;\n",
        "            }\n",
        "\n",
        "            formData.append('file', fileInput.files[0]);\n",
        "            showLoading();\n",
        "\n",
        "            fetch('/upload', {\n",
        "                method: 'POST',\n",
        "                body: formData\n",
        "            })\n",
        "            .then(response => response.json())\n",
        "            .then(data => {\n",
        "                hideLoading();\n",
        "                if (data.success) {\n",
        "                    updateDataInfo(data);\n",
        "                    updateColumnSelects(data.columns);\n",
        "                    showDataPreview(data.preview);\n",
        "                } else {\n",
        "                    alert('Error: ' + data.error);\n",
        "                }\n",
        "            })\n",
        "            .catch(error => {\n",
        "                hideLoading();\n",
        "                alert('Error uploading file: ' + error);\n",
        "            });\n",
        "        });\n",
        "\n",
        "        // Load sample data\n",
        "        function loadSampleData() {\n",
        "            showLoading();\n",
        "            fetch('/load_sample')\n",
        "            .then(response => response.json())\n",
        "            .then(data => {\n",
        "                hideLoading();\n",
        "                if (data.success) {\n",
        "                    updateDataInfo(data);\n",
        "                    updateColumnSelects(data.columns);\n",
        "                    showDataPreview(data.preview);\n",
        "                } else {\n",
        "                    alert('Error: ' + data.error);\n",
        "                }\n",
        "            })\n",
        "            .catch(error => {\n",
        "                hideLoading();\n",
        "                alert('Error loading sample data: ' + error);\n",
        "            });\n",
        "        }\n",
        "\n",
        "        // Update data info display\n",
        "        function updateDataInfo(data) {\n",
        "            document.getElementById('dataInfo').innerHTML = `\n",
        "                <div class=\"metric-card mb-2\">\n",
        "                    <h3>${data.rows}</h3>\n",
        "                    <p>Total Rows</p>\n",
        "                </div>\n",
        "                <div class=\"metric-card mb-2\">\n",
        "                    <h3>${data.cols}</h3>\n",
        "                    <p>Total Columns</p>\n",
        "                </div>\n",
        "            `;\n",
        "        }\n",
        "\n",
        "        // Update column select dropdowns\n",
        "        function updateColumnSelects(columns) {\n",
        "            var textCols = columns.text || [];\n",
        "            var numCols = columns.numeric || [];\n",
        "\n",
        "            ['textColumns', 'cleanTextColumns'].forEach(id => {\n",
        "                var select = document.getElementById(id);\n",
        "                select.innerHTML = textCols.map(c => `<option value=\"${c}\">${c}</option>`).join('');\n",
        "            });\n",
        "\n",
        "            ['numericColumns', 'cleanNumericColumns'].forEach(id => {\n",
        "                var select = document.getElementById(id);\n",
        "                select.innerHTML = numCols.map(c => `<option value=\"${c}\" selected>${c}</option>`).join('');\n",
        "            });\n",
        "        }\n",
        "\n",
        "        // Show data preview\n",
        "        function showDataPreview(preview) {\n",
        "            document.getElementById('dataPreview').style.display = 'block';\n",
        "            document.getElementById('previewTable').innerHTML = preview;\n",
        "        }\n",
        "\n",
        "        // Analyze data\n",
        "        function analyzeData() {\n",
        "            showLoading();\n",
        "            var params = {\n",
        "                similarity_threshold: document.getElementById('similarityThreshold').value,\n",
        "                n_clusters: document.getElementById('nClusters').value,\n",
        "                text_columns: Array.from(document.getElementById('textColumns').selectedOptions).map(o => o.value),\n",
        "                numeric_columns: Array.from(document.getElementById('numericColumns').selectedOptions).map(o => o.value)\n",
        "            };\n",
        "\n",
        "            fetch('/analyze', {\n",
        "                method: 'POST',\n",
        "                headers: {'Content-Type': 'application/json'},\n",
        "                body: JSON.stringify(params)\n",
        "            })\n",
        "            .then(response => response.json())\n",
        "            .then(data => {\n",
        "                hideLoading();\n",
        "                if (data.success) {\n",
        "                    displayAnalysisResults(data);\n",
        "                } else {\n",
        "                    alert('Error: ' + data.error);\n",
        "                }\n",
        "            })\n",
        "            .catch(error => {\n",
        "                hideLoading();\n",
        "                alert('Error analyzing data: ' + error);\n",
        "            });\n",
        "        }\n",
        "\n",
        "        // Display analysis results\n",
        "        function displayAnalysisResults(data) {\n",
        "            var html = `\n",
        "                <div class=\"row mb-4\">\n",
        "                    <div class=\"col\">\n",
        "                        <div class=\"metric-card\">\n",
        "                            <h3>${data.analysis.exact_duplicates}</h3>\n",
        "                            <p>Exact Duplicates</p>\n",
        "                        </div>\n",
        "                    </div>\n",
        "                    <div class=\"col\">\n",
        "                        <div class=\"metric-card\">\n",
        "                            <h3>${data.analysis.text_duplicates}</h3>\n",
        "                            <p>Text Duplicates</p>\n",
        "                        </div>\n",
        "                    </div>\n",
        "                    <div class=\"col\">\n",
        "                        <div class=\"metric-card\">\n",
        "                            <h3>${data.analysis.near_duplicates_kmeans}</h3>\n",
        "                            <p>K-means Duplicates</p>\n",
        "                        </div>\n",
        "                    </div>\n",
        "                    <div class=\"col\">\n",
        "                        <div class=\"metric-card\">\n",
        "                            <h3>${data.analysis.near_duplicates_knn}</h3>\n",
        "                            <p>KNN Duplicates</p>\n",
        "                        </div>\n",
        "                    </div>\n",
        "                    <div class=\"col\">\n",
        "                        <div class=\"metric-card\">\n",
        "                            <h3>${data.analysis.classification_duplicates}</h3>\n",
        "                            <p>Classification Duplicates</p>\n",
        "                        </div>\n",
        "                    </div>\n",
        "                </div>\n",
        "                <div class=\"card\">\n",
        "                    <div class=\"card-header\">\n",
        "                        <i class=\"fas fa-file-alt me-2\"></i>Detailed Report\n",
        "                    </div>\n",
        "                    <div class=\"card-body\">\n",
        "                        <div class=\"report-box\">${data.report}</div>\n",
        "                    </div>\n",
        "                </div>\n",
        "            `;\n",
        "            document.getElementById('analysisResults').innerHTML = html;\n",
        "        }\n",
        "\n",
        "        // Clean data\n",
        "        function cleanData() {\n",
        "            showLoading();\n",
        "            var params = {\n",
        "                method: document.getElementById('cleanMethod').value,\n",
        "                similarity_threshold: document.getElementById('similarityThreshold').value,\n",
        "                text_columns: Array.from(document.getElementById('cleanTextColumns').selectedOptions).map(o => o.value),\n",
        "                numeric_columns: Array.from(document.getElementById('cleanNumericColumns').selectedOptions).map(o => o.value)\n",
        "            };\n",
        "\n",
        "            fetch('/clean', {\n",
        "                method: 'POST',\n",
        "                headers: {'Content-Type': 'application/json'},\n",
        "                body: JSON.stringify(params)\n",
        "            })\n",
        "            .then(response => response.json())\n",
        "            .then(data => {\n",
        "                hideLoading();\n",
        "                if (data.success) {\n",
        "                    displayCleanResults(data);\n",
        "                } else {\n",
        "                    alert('Error: ' + data.error);\n",
        "                }\n",
        "            })\n",
        "            .catch(error => {\n",
        "                hideLoading();\n",
        "                alert('Error cleaning data: ' + error);\n",
        "            });\n",
        "        }\n",
        "\n",
        "        // Display clean results\n",
        "        function displayCleanResults(data) {\n",
        "            var html = `\n",
        "                <div class=\"alert alert-success\">\n",
        "                    <i class=\"fas fa-check-circle me-2\"></i>\n",
        "                    Successfully removed ${data.removed_count} duplicate entries!\n",
        "                </div>\n",
        "                <div class=\"row mb-4\">\n",
        "                    <div class=\"col-md-6\">\n",
        "                        <div class=\"metric-card\">\n",
        "                            <h3>${data.original_rows}</h3>\n",
        "                            <p>Original Rows</p>\n",
        "                        </div>\n",
        "                    </div>\n",
        "                    <div class=\"col-md-6\">\n",
        "                        <div class=\"metric-card\">\n",
        "                            <h3>${data.cleaned_rows}</h3>\n",
        "                            <p>Cleaned Rows</p>\n",
        "                        </div>\n",
        "                    </div>\n",
        "                </div>\n",
        "                <div class=\"card\">\n",
        "                    <div class=\"card-header\">\n",
        "                        <i class=\"fas fa-table me-2\"></i>Cleaned Data Preview\n",
        "                    </div>\n",
        "                    <div class=\"card-body\">\n",
        "                        <div class=\"table-responsive\">${data.preview}</div>\n",
        "                    </div>\n",
        "                </div>\n",
        "                <a href=\"/download\" class=\"btn btn-success mt-3\">\n",
        "                    <i class=\"fas fa-download me-2\"></i>Download Cleaned Dataset\n",
        "                </a>\n",
        "            `;\n",
        "            document.getElementById('cleanResults').innerHTML = html;\n",
        "        }\n",
        "\n",
        "        // Show cluster visualization\n",
        "        function showClusterVisualization() {\n",
        "            showLoading();\n",
        "            fetch('/visualize_clusters', {\n",
        "                method: 'POST',\n",
        "                headers: {'Content-Type': 'application/json'},\n",
        "                body: JSON.stringify({\n",
        "                    numeric_columns: Array.from(document.getElementById('numericColumns').selectedOptions).map(o => o.value)\n",
        "                })\n",
        "            })\n",
        "            .then(response => response.json())\n",
        "            .then(data => {\n",
        "                hideLoading();\n",
        "                if (data.success && data.image) {\n",
        "                    document.getElementById('clusterViz').innerHTML =\n",
        "                        '<img src=\"data:image/png;base64,' + data.image + '\" alt=\"Cluster Visualization\">';\n",
        "                } else {\n",
        "                    document.getElementById('clusterViz').innerHTML =\n",
        "                        '<div class=\"alert alert-warning\">' + (data.error || 'Could not generate visualization') + '</div>';\n",
        "                }\n",
        "            })\n",
        "            .catch(error => {\n",
        "                hideLoading();\n",
        "                alert('Error: ' + error);\n",
        "            });\n",
        "        }\n",
        "\n",
        "        // Compare models\n",
        "        function compareModels() {\n",
        "            showLoading();\n",
        "            fetch('/compare_models', {\n",
        "                method: 'POST',\n",
        "                headers: {'Content-Type': 'application/json'},\n",
        "                body: JSON.stringify({\n",
        "                    numeric_columns: Array.from(document.getElementById('numericColumns').selectedOptions).map(o => o.value)\n",
        "                })\n",
        "            })\n",
        "            .then(response => response.json())\n",
        "            .then(data => {\n",
        "                hideLoading();\n",
        "                if (data.success && data.image) {\n",
        "                    var html = '<img src=\"data:image/png;base64,' + data.image + '\" alt=\"Model Comparison\">';\n",
        "                    if (data.results) {\n",
        "                        html += '<table class=\"table mt-3\"><thead><tr><th>Model</th><th>Accuracy</th></tr></thead><tbody>';\n",
        "                        for (var model in data.results) {\n",
        "                            html += '<tr><td>' + model + '</td><td>' + data.results[model].toFixed(4) + '</td></tr>';\n",
        "                        }\n",
        "                        html += '</tbody></table>';\n",
        "                    }\n",
        "                    document.getElementById('modelComparison').innerHTML = html;\n",
        "                } else {\n",
        "                    document.getElementById('modelComparison').innerHTML =\n",
        "                        '<div class=\"alert alert-warning\">' + (data.error || 'Could not compare models') + '</div>';\n",
        "                }\n",
        "            })\n",
        "            .catch(error => {\n",
        "                hideLoading();\n",
        "                alert('Error: ' + error);\n",
        "            });\n",
        "        }\n",
        "    </script>\n",
        "</body>\n",
        "</html>\n",
        "'''\n",
        "\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template_string(HTML_TEMPLATE)\n",
        "\n",
        "\n",
        "@app.route('/upload', methods=['POST'])\n",
        "def upload_file():\n",
        "    try:\n",
        "        file = request.files['file']\n",
        "        if file and file.filename.endswith('.csv'):\n",
        "            df = pd.read_csv(file)\n",
        "            app_data['df'] = df\n",
        "\n",
        "            preview_html = df.head(10).to_html(classes='table table-striped table-hover', index=False)\n",
        "\n",
        "            return jsonify({\n",
        "                'success': True,\n",
        "                'rows': len(df),\n",
        "                'cols': len(df.columns),\n",
        "                'columns': {\n",
        "                    'text': df.select_dtypes(include=['object']).columns.tolist(),\n",
        "                    'numeric': df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "                },\n",
        "                'preview': preview_html\n",
        "            })\n",
        "        return jsonify({'success': False, 'error': 'Invalid file format'})\n",
        "    except Exception as e:\n",
        "        return jsonify({'success': False, 'error': str(e)})\n",
        "\n",
        "\n",
        "@app.route('/load_sample', methods=['GET'])\n",
        "def load_sample():\n",
        "    try:\n",
        "        sample_data = {\n",
        "            'Name': ['John', 'Jane', 'John', 'Bob', 'Jane', 'Alice', 'Charlie', 'John'],\n",
        "            'Age': [25, 30, 25, 35, 30, 28, 40, 25],\n",
        "            'City': ['NYC', 'LA', 'NYC', 'Chicago', 'LA', 'Boston', 'Seattle', 'NYC'],\n",
        "            'Salary': [50000, 60000, 50000, 70000, 60000, 55000, 80000, 50000],\n",
        "            'Department': ['IT', 'HR', 'IT', 'Finance', 'HR', 'Marketing', 'IT', 'IT']\n",
        "        }\n",
        "        df = pd.DataFrame(sample_data)\n",
        "        app_data['df'] = df\n",
        "\n",
        "        preview_html = df.to_html(classes='table table-striped table-hover', index=False)\n",
        "\n",
        "        return jsonify({\n",
        "            'success': True,\n",
        "            'rows': len(df),\n",
        "            'cols': len(df.columns),\n",
        "            'columns': {\n",
        "                'text': df.select_dtypes(include=['object']).columns.tolist(),\n",
        "                'numeric': df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "            },\n",
        "            'preview': preview_html\n",
        "        })\n",
        "    except Exception as e:\n",
        "        return jsonify({'success': False, 'error': str(e)})\n",
        "\n",
        "\n",
        "@app.route('/analyze', methods=['POST'])\n",
        "def analyze():\n",
        "    try:\n",
        "        if app_data['df'] is None:\n",
        "            return jsonify({'success': False, 'error': 'No data loaded'})\n",
        "\n",
        "        params = request.json\n",
        "        df = app_data['df']\n",
        "\n",
        "        remover = CombinedDuplicateRemover(\n",
        "            similarity_threshold=float(params.get('similarity_threshold', 0.9))\n",
        "        )\n",
        "        remover.text_remover.n_clusters = min(\n",
        "            int(params.get('n_clusters', 10)),\n",
        "            len(df)\n",
        "        )\n",
        "\n",
        "        text_cols = params.get('text_columns', [])\n",
        "        numeric_cols = params.get('numeric_columns', [])\n",
        "\n",
        "        analysis = remover.analyze_dataset(\n",
        "            df,\n",
        "            text_columns=text_cols if text_cols else None,\n",
        "            numeric_columns=numeric_cols if numeric_cols else None\n",
        "        )\n",
        "        app_data['analysis'] = analysis\n",
        "\n",
        "        report = remover.generate_report(analysis)\n",
        "\n",
        "        return jsonify({\n",
        "            'success': True,\n",
        "            'analysis': {\n",
        "                'total_rows': analysis['total_rows'],\n",
        "                'exact_duplicates': analysis['exact_duplicates'],\n",
        "                'text_duplicates': analysis['text_duplicates'],\n",
        "                'near_duplicates_kmeans': analysis['near_duplicates_kmeans'],\n",
        "                'near_duplicates_knn': analysis['near_duplicates_knn'],\n",
        "                'classification_duplicates': analysis['classification_duplicates']\n",
        "            },\n",
        "            'report': report\n",
        "        })\n",
        "    except Exception as e:\n",
        "        return jsonify({'success': False, 'error': str(e)})\n",
        "\n",
        "\n",
        "@app.route('/clean', methods=['POST'])\n",
        "def clean():\n",
        "    try:\n",
        "        if app_data['df'] is None:\n",
        "            return jsonify({'success': False, 'error': 'No data loaded'})\n",
        "\n",
        "        params = request.json\n",
        "        df = app_data['df']\n",
        "        original_rows = len(df)\n",
        "\n",
        "        remover = CombinedDuplicateRemover(\n",
        "            similarity_threshold=float(params.get('similarity_threshold', 0.9))\n",
        "        )\n",
        "\n",
        "        text_cols = params.get('text_columns', [])\n",
        "        numeric_cols = params.get('numeric_columns', [])\n",
        "\n",
        "        cleaned_df, removed_count = remover.clean_dataset(\n",
        "            df,\n",
        "            text_columns=text_cols if text_cols else None,\n",
        "            numeric_columns=numeric_cols if numeric_cols else None,\n",
        "            method=params.get('method', 'kmeans')\n",
        "        )\n",
        "        app_data['cleaned_df'] = cleaned_df\n",
        "\n",
        "        preview_html = cleaned_df.head(10).to_html(classes='table table-striped table-hover', index=False)\n",
        "\n",
        "        return jsonify({\n",
        "            'success': True,\n",
        "            'original_rows': original_rows,\n",
        "            'cleaned_rows': len(cleaned_df),\n",
        "            'removed_count': removed_count,\n",
        "            'preview': preview_html\n",
        "        })\n",
        "    except Exception as e:\n",
        "        return jsonify({'success': False, 'error': str(e)})\n",
        "\n",
        "\n",
        "@app.route('/download')\n",
        "def download():\n",
        "    try:\n",
        "        if app_data['cleaned_df'] is None:\n",
        "            return \"No cleaned data available\", 404\n",
        "\n",
        "        buffer = io.BytesIO()\n",
        "        app_data['cleaned_df'].to_csv(buffer, index=False)\n",
        "        buffer.seek(0)\n",
        "\n",
        "        return send_file(\n",
        "            buffer,\n",
        "            mimetype='text/csv',\n",
        "            as_attachment=True,\n",
        "            download_name='cleaned_dataset.csv'\n",
        "        )\n",
        "    except Exception as e:\n",
        "        return str(e), 500\n",
        "\n",
        "\n",
        "@app.route('/visualize_clusters', methods=['POST'])\n",
        "def visualize_clusters():\n",
        "    try:\n",
        "        if app_data['df'] is None:\n",
        "            return jsonify({'success': False, 'error': 'No data loaded'})\n",
        "\n",
        "        params = request.json\n",
        "        numeric_cols = params.get('numeric_columns', [])\n",
        "\n",
        "        if not numeric_cols:\n",
        "            numeric_cols = app_data['df'].select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "        if len(numeric_cols) < 2:\n",
        "            return jsonify({'success': False, 'error': 'Need at least 2 numeric columns'})\n",
        "\n",
        "        remover = TabularDuplicateRemover()\n",
        "        fig = remover.visualize_clusters(app_data['df'], numeric_cols)\n",
        "\n",
        "        if fig:\n",
        "            img_base64 = fig_to_base64(fig)\n",
        "            return jsonify({'success': True, 'image': img_base64})\n",
        "        else:\n",
        "            return jsonify({'success': False, 'error': 'Could not generate visualization'})\n",
        "    except Exception as e:\n",
        "        return jsonify({'success': False, 'error': str(e)})\n",
        "\n",
        "\n",
        "@app.route('/compare_models', methods=['POST'])\n",
        "def compare_models():\n",
        "    try:\n",
        "        if app_data['df'] is None:\n",
        "            return jsonify({'success': False, 'error': 'No data loaded'})\n",
        "\n",
        "        params = request.json\n",
        "        numeric_cols = params.get('numeric_columns', [])\n",
        "\n",
        "        if not numeric_cols:\n",
        "            numeric_cols = app_data['df'].select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "        detector = ClassificationDuplicateDetector()\n",
        "        results = detector.compare_models(app_data['df'], numeric_cols)\n",
        "\n",
        "        if results:\n",
        "            fig = detector.plot_model_comparison(results)\n",
        "            img_base64 = fig_to_base64(fig) if fig else None\n",
        "            return jsonify({\n",
        "                'success': True,\n",
        "                'results': results,\n",
        "                'image': img_base64\n",
        "            })\n",
        "        else:\n",
        "            return jsonify({'success': False, 'error': 'Could not compare models'})\n",
        "    except Exception as e:\n",
        "        return jsonify({'success': False, 'error': str(e)})\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=False, port=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "he4x9R9J54Ha",
        "outputId": "03b04584-0a61-4de8-fcf4-504931ae54fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing flask_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CELL 6: Alternative - Run Streamlit with ngrok (Requires free signup)\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "# Set your ngrok auth token (get free token from https://ngrok.com/)\n",
        "ngrok.set_auth_token(\"YOUR NGROK TOKEN\")\n",
        "\n",
        "# Kill any existing processes\n",
        "!pkill -f streamlit\n",
        "!pkill -f ngrok\n",
        "\n",
        "# # Start Streamlit\n",
        "streamlit_process = subprocess.Popen(\n",
        "     ['streamlit', 'run', 'streamlit_app.py', '--server.port', '8501', '--server.headless', 'true'],\n",
        "     stdout=subprocess.PIPE,\n",
        "     stderr=subprocess.PIPE\n",
        " )\n",
        "\n",
        "time.sleep(5)\n",
        "\n",
        " # Create ngrok tunnel\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"\\n{'=' * 50}\")\n",
        "print(f\"üöÄ Streamlit App is running at: {public_url}\")\n",
        "print(f\"{'=' * 50}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLZxNSos6CI9",
        "outputId": "17909089-c4d1-460a-d21b-598cfb9a88b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "üöÄ Streamlit App is running at: NgrokTunnel: \"https://unprodded-yevette-philosophically.ngrok-free.dev\" -> \"http://localhost:8501\"\n",
            "==================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CELL 7: Run Flask Application\n",
        "# =============================================================================\n",
        "\n",
        "# Method 1: Using flask-ngrok (Recommended)\n",
        "print(\"Starting Flask application...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# For Flask with ngrok\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "\n",
        "# Uncomment the line below and add your ngrok token\n",
        "ngrok.set_auth_token(\"36mwqliJIfWr7EXqhrdpuPoCr9w_sfvUA2Dxpr4oP7gShMmE\")\n",
        "\n",
        "# Import Flask app\n",
        "from flask_app import app\n",
        "\n",
        "# Start ngrok tunnel\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"\\nüöÄ Flask App is running at: {public_url}\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Run Flask app\n",
        "app.run(port=5000)"
      ],
      "metadata": {
        "id": "6iK3EwPN6rUU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "8d87ca32-754d-4bb1-ac5e-2e57a5f32c7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Flask application...\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'flask_app'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3818445651.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Import Flask app\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mflask_app\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Start ngrok tunnel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'flask_app'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3IdBvs-7B775"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
